<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Virtual Try-On FaceMesh</title>
    <style>
        body {
            background: #111;
            color: #fff;
            text-align: center;
        }

        video,
        canvas {
            margin-top: 20px;
            border: 2px solid #28a745;
            border-radius: 10px;
        }

        #startBtn {
            margin-top: 20px;
            padding: 10px 20px;
            background: #28a745;
            border: none;
            border-radius: 6px;
            color: #fff;
            font-size: 18px;
            cursor: pointer;
        }
    </style>
</head>

<body>
    <h1>ðŸ‘“ Virtual Try-On (Face Aligned)</h1>
    <button id="startBtn">Start Camera</button><br>
    <video id="video" width="640" height="480" autoplay muted playsinline style="display:none;"></video>
    <canvas id="canvas" width="640" height="480"></canvas>

    <!-- Mediapipe -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>

    <script>
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        const startBtn = document.getElementById("startBtn");

        const glasses = new Image();
        glasses.src = "https://i.ibb.co/sb1Y1XJ/sunglasses.png"; // ðŸ‘“ apni PNG

        let faceMesh;

        async function startCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            video.style.display = "block";

            faceMesh = new FaceMesh.FaceMesh({
                locateFile: (file) => {
                    return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
                }
            });

            faceMesh.setOptions({
                maxNumFaces: 1,
                refineLandmarks: true,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });

            faceMesh.onResults(onResults);

            // Loop
            async function detect() {
                await faceMesh.send({ image: video });
                requestAnimationFrame(detect);
            }
            detect();
        }

        function onResults(results) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                const landmarks = results.multiFaceLandmarks[0];

                // Eyes: 33 (left), 263 (right)
                const leftEye = landmarks[33];
                const rightEye = landmarks[263];

                if (leftEye && rightEye) {
                    const eyeX1 = leftEye.x * canvas.width;
                    const eyeY1 = leftEye.y * canvas.height;
                    const eyeX2 = rightEye.x * canvas.width;

                    const glassesWidth = Math.abs(eyeX2 - eyeX1) * 2.5;
                    const glassesHeight = glassesWidth / 2;

                    const x = eyeX1 - (glassesWidth / 4);
                    const y = eyeY1 - (glassesHeight / 2);

                    ctx.drawImage(glasses, x, y, glassesWidth, glassesHeight);
                }
            }
        }

        startBtn.addEventListener("click", startCamera);
    </script>
</body>

</html>
